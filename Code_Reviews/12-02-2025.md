Deeper Code Review of backend logic and files:

In the imports SQLModel, Field, and Sessions are the core pieces of SQLModel ORM. contextmanager are for the session provider. load_dotenv is used for loading the .env file for the backend. SQLModel is a hybrid mix of Pydantic and SQLAlchemy.

when loading the .env __file__ defines the current file, when locating the .env file for backend goes up for 4 levels from the project root, hence the long line of os.path.dirname. if the files will be moved in the future it would cause an error so the best practice for this would be BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../"))
dotenv_path = os.path.join(BASE_DIR, ".env") instead of BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
dotenv_path = os.path.join(BASE_DIR, ".env")

print(f"Looking for .env at: {dotenv_path}")
print(f".env exists: {os.path.exists(dotenv_path)}")
print(f"DATABASE_URL loaded: {DATABASE_URL}")

those files are great for debugging or for project building, but once in the production phase it must be removed, since it will leak confidential data that are used within the backend.

engine = create_engine(DATABASE_URL, echo=True)

echo=True prints raw SQL queries, which is good for learning, echo should only be used in development phase

when creating the User Model specifying the __tablename__ and __table_args__ is a good practice since SQLModel will create the schema if it doesn't already exists

when it comes to handling passwords or user keys it must always be stored as hash, and never plain text.

class Journal(SQLModel, table = True):
    __table_args__ = {"schema": "journal"}
user_id : int = Field(foreign_key = "auth.users.id")

the setup of that code block is great, but the problem later would be SQLModel will generate contraints based on it, in order to solve that problem we can ad a relationship later 
user: User = Relationship(back_populates="journal_entries")

def create_db_and_tables():
    SQLModel.metadata.create_all(engine)

the code snippet does not create schemas, and only creates tables, so before starting it must be created in PostgreSQL first. 

@contextmanager
def get_session():
    with Session(engine) as session:
        yield session

with this code block context-managed session factory is created and it ensures session opens, DB operations happen, session closes automatically rollback on error, cleanup always guaranteed. howeverm, t is not compatible with FastAPI's dependency inhection design

def get_session_dependency():
    with Session(engine) as session:
        yield session

since get_session(): is incorrect, i created a get_sesion_dependency, since FastAPI requires generator functions for dependncies.

the mistake is that I forgot to remove get_session() and have both it and get_sessio_dependency()

auth_utils.py

in the imports:
using passlib for hashing password is the industry's standard.
jose for JWT is common in Python APIs. OAuth2PasswordBearer integrates perfectly with FastAPI dependencies. displaying sensitive information inside the .env is dangerous, must be removed for production.

oauth2_scheme = OAuth2PasswordBearer(tokenUrl="/api/login")

To get a token, clients must POST to /api/login with email and password. the value automatically apears in the Swagger UI, tokenUrl must watch the actual login route.

pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

since bcrypt is secure it is a wiser choice, auto ensures forward compatibility. and this snippet follow exact security best practices: 
def hash_password(password: str) -> str:
    return pwd_context.hash(password)

def verify_password(password: str, hashed_password: str) -> bool:
    return pwd_context.verify(password, hashed_password)


def create_access_token(data: dict, expires_delta: int | None = None) -> str:
    to_encode = data.copy()
    expire = datetime.utcnow() + timedelta(minutes = expires_delta or ACCESS_TOKEN_EXPIRE_MINUTES)
    to_encode.update({"exp": expire})
    return jwt.encode(to_encode, SECRET_KEY, algorithm = ALGORITHM)

when creating a JWT it must always have an expiration, it must also copy and update the payload, and also uses correct JWT format.

when designing the dependency for get_current_user() it must have the exact token, decode it properly, and validate it, then return the user ID. there are missing steps, it is only returning the user_id, most apps return User model instance.

suggestions and ratings of auth_utils.py
What you got very right:
    Your password hashing is textbook perfect.
    JWT creation is correct.
    OAuth2 bearer is correctly used as a dependency.
    Security errors follow proper HTTP standards.
    Code is readable and simple.

What is needed to improve
High priority
    Centralize config (SECRET_KEY, DB URL)
    Remove duplicated .env loading
    Validate SECRET_KEY & DATABASE_URL
    Update tokenUrl to match real route path
Medium priority
    Add "iat" to JWT payload
    Simplify .env path logic
    Remove debug prints in production
Optional (advanced)
    Make get_current_user return full User object instead of just id.

auth_routes.py

clean imports, excellent usage of sqlmodel. but CryptContext is imported but was not used, so it is safe to remove it (migh remove it later).

once again get_session() was imported but was not used, and manually did with Session(engine) as session. for best practices, it is better use FastAPI dependencies like in get_session_dependency() from earlier. the setup of router = APIRouter() is simple and correct.

for the api when registering a user: using UserCreate Pydantic model ensures validation, and it is good practice when checking for the email uniqueness to prevent email duplication. adding an optional username when creating a user is well thought.

while creating the user the email checking is using a correct query, the .first() is used correctly, the error code 400 is also correct.

while creating the user since the username is an optional field it used a somewhat similar logic to the email checking logic, but what makes it different is since it is an optional field it still validates it nonetheless and username is only checked if provided.

note from gpt: instead of checking email and username separately, consider applying unique constraints in the SQLModel User class. that way your DB enforces uniqueness, and your API only handles validation (I will look into it later, and try to apply this logic)

new_user = User(...) is for creating the new user and it is correct, it is hashing HTML users' password correctly via utility function.

when it comes to commiting and refreshing the User to be updated in the database this code snippet is correct 
session.add(new_user)
session.commit()
session.refresh(new_user)

HTTP Request POST /login
an API for user login, the response model is good. Lookup User is decent but an improvement should be accepted specially when allowing login with username OR email in the future.

when checking for invalid credentials, the logic is clean and secure, generic error message is good and might prevent user enumeration attacks.

when creating a Token, this code snippet

token = create_access_token({
    "sub" : str(db_user.id),
    "email" : db_user.email,
    "username" : db_user.username
})

 has a good payload, use "sub" only for user ID, store other fields under "data" or "claims", not required but it is far cleaner.

 auth_models.py

 the models are Pydantic-only and not SQLModel, but none of these models represent actual tables. It is correct, because request/response models should not inherit from the Database. Good practice is followed but using SQLModel is overkill for request-body models. Currently not using any SQLModel-specific features (no Field, no table=True, and no relationships). a better option would be to use Pydantic BaseModel instead of SQLModel (it is Faster, cleaner, and no confusion between Database schemas and API schemas) (if can applly later do so.)

 in the current code, it is returning models that expose email and username correctly, but it is missing a common Pydantic pattern. so if we look at 

 class UserRead(SQLModel):
    id: int
    username: str | None = None
    email: str

there is nothing wrong, but it is missing:

class Config:
    from_attributes = True

otherwise UserReam.from_orm() may fail, and in SQLModel it's not a guarantee. Enen if it is not using from_orm() yet, it will later when it returns User objects.

a recommended fix would be 

class UserRead(BaseModel):
    id: int
    username: str | None = None
    email: str

    model_config = {"from_attributes": True}

in registration model, it exposes password, this is normal but ensure to never return it. currently the code is 

class UserCreate(SQLModel):
    email: str
    username: str | None = None
    password: str

it is correct for incoming requests. but make it a hundred percent sure that it never accidentally return UserCreate anywhere, the routes are safe so far, but the rule: Never return a password field model to the client, and only return UserRead or Token.

currently the Token model is correct, but there is something missing. and that is the epiration info. the login route returns only

access_token: str
token_type: str

most systems return: 

expires_in: number

although it is optional, but it is useful for frontend

currently the login model is correct by logic, nothing to improve for now. it is clean, minimal, and correct

the current code:

from sqlmodel import SQLModel

class UserCreate(SQLModel):
    # I decided to add a username but make it optional
    email : str
    username : str | None = None
    password : str
    
class UserRead(SQLModel):
    # I need to make the UserRead None username otherwise it will raise an error
    id: int
    username: str | None = None
    email: str

class UserLogin(SQLModel):
    email: str
    password: str

class Token(SQLModel):
    access_token: str
    token_type: str = "bearer"


# apply this later to see if it breaks or not
# a faster, cleaner, and confusion free code

# from pydantic import BaseModel

# class UserCreate(BaseModel):
#     # I decided to add a username but make it optional
#     email : str
#     username : str | None = None
#     password : str
    
# class UserRead(BaseModel):
#     # I need to make the UserRead None username otherwise it will raise an error
#     id: int
#     username: str | None = None
#     email: str

# class UserLogin(BaseModel):
#     email: str
#     password: str

# class Token(BaseModel):
#     access_token: str
#     token_type: str = "bearer"

but can be changed later to:

from pydantic import BaseModel

class UserCreate(BaseModel):
    email: str
    username: str | None = None
    password: str

class UserRead(BaseModel):
    id: int
    username: str | None = None
    email: str

    model_config = {"from_attributes": True}

class UserLogin(BaseModel):
    email: str
    password: str

class Token(BaseModel):
    access_token: str
    token_type: str = "bearer"
    # Optional but recommended:
    # expires_in: int = 3600

journal_routes.py

the structure is decent. Authentication is enforced. and Database session is used properly. there are only a few important improvements that can be implemented.

the GET /journal route is correct, however it must return a response model, currently it is 

@router.get("/journal")
def list_of_trades(...):
    return trades

this returns raw SQLModel table objects, it includes fields frontend should not see (like foreign keys). it is better to use a response model such as: List[JournalRead], an example would be:

@router.get("/journal", response_model=list[JournalRead])

the reasons are for it to sanitize the fields, auto generate OpenAPI docs, protect schema from leaking internal fields, and ensure consistent output structure.

The POST /register/trade route structure is correct, however it is better to rename the route. currently it is /register/trade this is not RESTful. the correct naming would be to use journal instead of register

POST /journal/trades and an example would be

@router.post("/journal", response_model=JournalRead)

Validating the user_id binding should happen inside the Journal model. currently it is manually doing it

new_trade = Journal(
    user_id = current_user,
    ...
)

although it is correct, but precations must be implemented, since i need to be aware that user should never be able to set user_id from frontend, but in the CreateTrade model, user_id doesn't exist, so currentl;y it is safe (but it might become alarming if it is)

Adding try/except around commit to catch DB integrity errors. for example, adding duplicate trade, invalid date formats, missing asset_coin, etc. recommended fix would be:

try:
    session.add(new_trade)
    session.commit()
    session.refresh(new_trade)
except Exception as e:
    session.rollback()
    raise HTTPException(status_code=500, detail="Unable to create trade")

it still is optional at this stage, but helpful to consider.

There could be a minor improvement in returning the created object instead of a custom message. instead of saying

return {"message": "New Trade Created successfully", "trade id": new_trade.id}

we can return the full trade like this

return new_trade

or with a response_model:

return JournalRead.from_orm(new_trade)

a recommended improved version by ChatGPT a clean and RESTful version

from fastapi import APIRouter, Depends, HTTPException
from sqlmodel import Session, select
from backend.app.core.database import get_session_dependency, Journal
from backend.app.model.journal_models import CreateTrade, JournalRead
from backend.app.core.auth_utils import get_current_user

router = APIRouter()


@router.get("/journal", response_model=list[JournalRead])
def list_of_trades(
    current_user: int = Depends(get_current_user),
    session: Session = Depends(get_session_dependency)
):
    trades = session.exec(
        select(Journal).where(Journal.user_id == current_user)
    ).all()
    return trades


@router.post("/journal", response_model=JournalRead)
def register_trade(
    journal_info: CreateTrade,
    current_user: int = Depends(get_current_user),
    session: Session = Depends(get_session_dependency)
):
    new_trade = Journal(
        user_id=current_user,
        **journal_info.dict()
    )
    
    session.add(new_trade)
    session.commit()
    session.refresh(new_trade)

    return new_trade

journal_model.py 

this short script is okay but it feels like it is missing the database model (Journal), currently it only have the 

class CreateTrade(SQLModel):

that is only the request body model, not the table. but inside the routes, it used

from backend.app.core.database import Journal

so it already has a database model somewhere else, it is good, but there is a need to confirm consistency.

the naming for profit or loss should be improved, instead of p_l it could be pnl or is_profit, currently it is

p_l: bool | None = None

it is quite unclear, it could mean many things. is it profit/loos boolean, profit/loss positive or negative number, or is it the result of the trade? (although it is all, but it must be named properly, for best practices.)

another thing to consider for p_l is to make it a float instead of boolean, because if it is a float it has a broader scope for analytics not just True or False

a notable part of the logic in creating the trade is the date_open and date_closed. simply because of the reason that the trade might still be ongoing or complete.

There might be an issue to backend and frontend for field consistency, simply because of the camelCase and snake_case. for example in backend 

value_entered

and in frontend it is 

valueEntered

it must be mapped manually in the frontend unless renaming it based on the backend fields. it is not a problem, just a reminder.

a recommendation:

from sqlmodel import SQLModel
from datetime import date

class CreateTrade(SQLModel):
    asset_coin: str
    value_entered: float
    value_outcome: float
    date_open: date
    date_closed: date | None = None
    note: str | None = None
    strategy: str | None = None
    pnl: float | None = None    # BETTER THAN boolean

and if planning for analytics, the vest model improvement would be 

trade_type: str | None = None   # "long" or "short"
risk_reward: float | None = None
entry_price: float | None = None
exit_price: float | None = None

and also, always remember to alter the database tables first before running the code, so it won't run into error.

/backend/app/core/database.py

In the database.py, there is an issue, although it is structured well there are parts that are too noisy and risky (although understandable since it still in developent phase) and must be removed uring production

print(f"Looking for .env at: {dotenv_path}")
print(f".env exists: {os.path.exists(dotenv_path)}")
print(f"DATABASE_URL loaded: {DATABASE_URL}")

not only does it show where the files are, it also prints the secret in logs, a better version would be

load_dotenv(dotenv_path)
DATABASE_URL = os.getenv("DATABASE_URL")

if not DATABASE_URL:
    raise ValueError("DATABASE_URL not found in .env")

this sis a cleaner and safer version.

in the engine configuration, overall is okay, but echo=True slows production (research more about engines to deepen understanding) crrently is

engine = create_engine(DATABASE_URL, echo=True)

and a better version would be

engine = create_engine(DATABASE_URL, echo=False)

in the User Model, it's excellent not only are the schemas separated, index with unique emails, and an optional Username, but there is one mprovement that would add flavor to it. adding nullable=False (research this further) to email hashed_password for database safety example would be

email: str = Field(nullable=False, unique=True, index=True)
hashed_password: str = Field(nullable=False)

in Journal Model tthe issue with consistency is the p_l, making it a boolean would be limiting to upcoming features like in analytics, making it float would be better. a suggestion for it would be

pnl: float | None = None

Adding a nullable=False where appropriate would be beneficial to the system, These fields 

asset_coin: str = Field(nullable=False)
value_entered: float = Field(nullable=False)
value_outcome: float = Field(nullable=False)
date_open: date = Field(nullable=False)

Adding a timestamps is a good practice

created_at: datetime = Field(default_factory=datetime.utcnow)

Relationship is missing, although there is a foreign key, adding a relationship() is better. currently it is 

user_id: int = Field(foreign_key="auth.users.id")

it is crrent but if ORM navidgation is necessary

from sqlmodel import Relationship

class Journal(SQLModel, table=True):
    ...
    user: User = Relationship(back_populates="trades")

adding this to the logic is recommended if scaling is an option.

for Session management, this one is great. but notice that there are two version and the other one is working but te other is bugging

@contextmanager
def get_session()

def get_session_dependency()

def get_session_dependency() is the one that's working earlier but must double check later and clean up.

for creating tables, it must only run once and that is during app startup. so it is better to be placed inside the main.py

final improved version (must be checked later):

class Journal(SQLModel, table=True):
    __tablename__ = "journal_info"
    __table_args__ = {"schema": "journal"}

    id: int | None = Field(default=None, primary_key=True)
    user_id: int = Field(foreign_key="auth.users.id", nullable=False)

    asset_coin: str = Field(nullable=False)
    value_entered: float = Field(nullable=False)
    value_outcome: float = Field(nullable=False)
    date_open: date = Field(nullable=False)
    
    date_closed: date | None = None
    note: str | None = None
    strategy: str | None = None

    pnl: float | None = None  # FIXED

core/middleware.py

the middleware is functionally correct and uses the proper Starlette middleware pattern, not only does it capture requests and URL, but it also captures the status code. that is as good as an initial debugging tool. However, for production-level code it seems that there are critical improvements needed regarding logging, performance, privacy, and midleware pipeline behavior.

Using print() is a red flag in productions systems, and problems:

No log levels, No timestamps, No structured logs, cannot integrate with logging systems (ex. Graylog, Loki, Datadog, ELK, CLoudWatch. could be a good start to learn one these later.), Cannot filter logs, and No log rotation. to that note there is actually a Python logging module, example:

import logging
logger = logging.getLogger("app.middleware")

That should be the expected standard for any backend.