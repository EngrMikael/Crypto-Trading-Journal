/core/middleware.py 

full code:

from starlette.middleware.base import BaseHTTPMiddleware, RequestResponseEndpoint
from starlette.requests import Request
from starlette.responses import Response

class LogMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        print(f"Request: {request.method} {request.url}")
        response = await call_next(request)
        print(f"Response status: {response.status_code}")
        return response

code review:

from starlette.middleware.base import BaseHTTPMiddleware, RequestResponseEndpoint
from starlette.requests import Request
from starlette.responses import Response

these are the imports that will be used in middleware, all came from starlette and 3 different sub-packages.

class LogMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        print(f"Request: {request.method} {request.url}")
        response = await call_next(request)
        print(f"Response status: {response.status_code}")
        return response

created a class for a logging middleware that inherits from Starlette's base called BaseHTTPMiddleware, it uses a async instead of the normal def for the sole reason of efficiency. we can view async as a multitasker of some sort, while waiting for the action it takes on another request, unlike the good-old def it waits for the process to finish before proceeding to the next request. dispatch uses self, request: Request, and call_next. I also created a variable that waits for the next request using await call_next(request), now we can print the status of the response using response.status_code, then we return response

so basically, middleware class inherits from Starlette's  BaseHTTPMiddleware, which it defines the structure for handling requests and responses inside FastAPI.

dispatch is defined as asyinc because FastAPI/Starlette is built around asynchronous I/O (input output). when we use asynf it makes it non-blocking, which means that while the middleware is waiting for I/O, the event loop switch to handling other incoming requests allowing the server to scale much more efficiently under load. if I used a normal def dispatch, it would block the entire worker until the response is fully processed, reducing concurrency.

the parameters, self refers to the current instance of the middleware class. request : Request if the incoming HTTP request object containing method, headers, URL, body, etc., call_next is a function that forwards the request to the next middleware or th actual endpoint, since this is async we must await it.

finally, this middleware logs incoming requests and its corresponding response status.